Week 3
1. Business Alignment 业务协调
2. Waterfall vs. Incremental vs. Spiral vs. Rad Model: Key Difference 表格对比特性
3. Top 6 software development models and how they influence the SDLC 迭代模型 敏捷模型 DevOps模型 waterfall模型, Verification and Validation, Spiral模型
4. The Ultimate Guide to IT Project Management: 项目管理定义(ITPM)， IT项目的六个阶段Initiation Definition Design Development Implementation Follow Up
5. IT Project Management：PM的责任，PM挑战，PM成功经验等，和4比较相关，可以一起查询

Week 4
1. What are sources?：一手信息，二手，三手（Tertiary sources）
2. Primary Research vs Secondary Research: Definitions, Differences, and Examples:一手research的类型如surveys，interviews，observation等5个；二手research的类型如academic peer-reviewed journals
3. Step-by-Step Guide & Research Rescue: Evaluating Credibility: 评估资料的可信度，从不同维度验证信息的可靠性
4. Why and how to use sources：为什么引用文献（n个点），怎么引用（2点）
5. External Analysis Research：和3讲的差不多，是相应的展开

Week 5
1. The Ultimate Guide to Project Tracking:PT是什么？Why use PT（4个优点）？如何高效PT？（n种方法）
2. Six Reasons Why Research Is Important：6个研究的重要性+如何提高研究能力
3. Differences Between Qualitative（定性） and Quantitative Research Methods:定性和定量研究方法，纯表格对比
4. Research Methods: What are research methods?定性定量混合三者定义+不同类型数据收集方法
5. The benefits of business analytics: 商业分析的五个好处+商业分析的三种类型





We use the same Kaggle notebook GPU environment to train this models.

From the parameter aspect, the VGG16 is the largest one, which contains 50.8M trainable parameters.  The SENet18's total parameters nearly two times of ResNet18. The large amount of parameters may be one reason for the VGG and SENet18 to be overfitted.  Maybe the models are too large but the training set is not large enough. We could use more advanced data augmentation methods like mixup to augment the training data. And tuning the Dropout rate and L2 norm to eliminate the overfitting problem.


In this project, we try to use three CNN models to solve the Cifar100 classification problem. We try our best to tuning the hyper-parameters such as batch size, learning rate, and decay rate etc. Through this project, we have improved our ability to build a CNN model use pytorch architecture and improved the understanding of hyper-parameters. And we are also familiar with the Cifar100 dataset and some image augmentation methods. 

In the future, we will try to use more advanced data augmentation methods like mixup to eliminate the overfitting problem. And we will also try to tunning other hyper parameters such as dropout rate, weight_decay rate, and optimizer methods, etc.

深度学习基础知识+代码
https://zh.d2l.ai/index.html

交叉熵损失函数：https://blog.csdn.net/bitcarmanlee/article/details/105619286
